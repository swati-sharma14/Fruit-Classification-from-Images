{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeYlwB1oRBvK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate the target variable\n",
        "y_train = train_df[\"category\"]\n",
        "X_train = train_df.drop([\"ID\", \"category\"], axis=1)\n",
        "X_test = test_df.drop([\"ID\"], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_train = X_train_standardized\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_train = X_train_standardized"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_neighbors': [5, 6, 7],\n",
        "    'algorithm': ['ball_tree'],\n",
        "    'metric': ['euclidean'],\n",
        "    'contamination': [0.01]\n",
        "}\n",
        "\n",
        "# Initialize the LOF algorithm\n",
        "lof = LocalOutlierFactor()\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(lof, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "lqP7MsRfSqbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the LOF algorithm on X_train\n",
        "lof = LocalOutlierFactor()\n",
        "outliers = lof.fit_predict(X_train)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_train[outliers==1]))\n",
        "\n",
        "# Remove the outliers from X_train and y_train\n",
        "X_train = X_train[outliers == 1]\n",
        "y_train = y_train[outliers == 1]"
      ],
      "metadata": {
        "id": "uuNildAqSttd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(grid_search.best_params_)\n",
        "\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "print(X_train_pca.shape)\n",
        "\n",
        "exp_var = sum(pca.explained_variance_ratio_ * 100)\n",
        "print('Variance explained:', exp_var)"
      ],
      "metadata": {
        "id": "8YmvxfxDSvhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis(n_components=19)\n",
        "X_train_pca = lda.fit_transform(X_train_pca, y_train)\n",
        "\n",
        "print(X_train_pca.shape)\n",
        "exp_var = sum(lda.explained_variance_ratio_ * 100)\n",
        "print('Variance explained:', exp_var)"
      ],
      "metadata": {
        "id": "nuDRc-83Swjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 8\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "kmeans.fit(X_train_pca)\n",
        "\n",
        "train_df_cluster_labels = kmeans.labels_\n",
        "\n",
        "X_train_clustered = pd.concat([pd.DataFrame(X_train_pca), pd.DataFrame(train_df_cluster_labels, columns=[\"cluster_label\"])], axis=1)"
      ],
      "metadata": {
        "id": "YbS2upyZSxqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "GXEC6E_HSy7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_clustered, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "log_reg1 = LogisticRegression(C=0.1, max_iter=1000)\n",
        "log_reg2 = LogisticRegression(C=0.01, max_iter=1000)\n",
        "log_reg3 = LogisticRegression(C=0.001, max_iter=1000)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr1', log_reg1), ('lr2', log_reg2), ('lr3', log_reg3)],\n",
        "    voting='soft',\n",
        "    weights=[2, 1, 1] \n",
        ")\n",
        "\n",
        "X_train.columns = X_train.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)\n",
        "\n",
        "scores = cross_val_score(voting_clf, X_train, y_train, cv=15)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of the ensemble model:\", accuracy)"
      ],
      "metadata": {
        "id": "m3x0zYO0S0L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the test data\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "X_test = test_df.drop([\"ID\"], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_standardized = scaler.fit_transform(X_test)\n",
        "X_test = X_test_standardized\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_standardized = scaler.fit_transform(X_test)\n",
        "X_test = X_test_standardized\n",
        "\n",
        "X_test_pca = pca.transform(X_test)\n",
        "X_test_pca = lda.transform(X_test_pca)\n",
        "\n",
        "test_df_cluster_labels = kmeans.predict(X_test_pca)\n",
        "X_test_clustered = pd.concat([pd.DataFrame(X_test_pca), pd.DataFrame(test_df_cluster_labels, columns=[\"cluster_label\"])], axis=1)\n",
        "\n",
        "X_test_clustered.columns = X_test_clustered.columns.astype(str)\n",
        "\n",
        "y_pred = voting_clf.predict(X_test_clustered)\n",
        "\n",
        "y_pred_decoded = le.inverse_transform(y_pred)\n",
        "\n",
        "submission_df = pd.DataFrame({'ID': test_df['ID'], 'category': y_pred_decoded})\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "o8Q7sz08S1hl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}